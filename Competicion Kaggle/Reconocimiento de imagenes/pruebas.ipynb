{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtencion de datos y Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_csv(csv_path, base_path):\n",
    "    data = read_csv(csv_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        img_path = row[1][1:]\n",
    "        label = row[2]\n",
    "        \n",
    "        # Abrir la imagen\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('L')  # Asegurarse de que esté en escala de grises\n",
    "            images.append(np.array(img))\n",
    "            labels.append(label)\n",
    "    \n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    return [img / 255.0 for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Definir las emociones\n",
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(emotions)\n",
    "\n",
    "def encode_labels(labels):\n",
    "    return label_encoder.transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    numeric_labels = encode_labels(labels)\n",
    "    return to_categorical(numeric_labels, num_classes=len(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, labels):\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = preprocess_labels(labels)\n",
    "    \n",
    "    # Normalizar las imágenes\n",
    "    images = normalize_images(images)\n",
    "    \n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/train_set.csv'\n",
    "base_path = './data/images/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_images_from_csv(csv_path, base_path)\n",
    "train_images, train_labels = preprocess_data(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_emotions(csv_path):\n",
    "    data = read_csv(csv_path)\n",
    "    emotion_counts = data.iloc[:, 2].value_counts()\n",
    "    return emotion_counts\n",
    "\n",
    "# Contar las frecuencias de cada emoción en el conjunto de entrenamiento\n",
    "emotion_counts = count_emotions(csv_path)\n",
    "plt.figure(figsize=(10, 6))\n",
    "emotion_counts.plot(kind='bar')\n",
    "plt.title('Frecuencia de Emociones en el Conjunto de Entrenamiento')\n",
    "plt.xlabel('Emoción')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las clases estan desbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandir dimensiones para incluir el canal de color\n",
    "train_images = np.expand_dims(train_images, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corregimos las clases desbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los pesos de clase\n",
    "numeric_labels = encode_labels([label_encoder.inverse_transform([np.argmax(label)])[0] for label in train_labels])\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(numeric_labels), y=numeric_labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(emotions))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generador de datos con aumentación\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 316ms/step - accuracy: 0.1391 - loss: 12.4861 - val_accuracy: 0.1112 - val_loss: 2.5641\n",
      "Epoch 2/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.0938 - loss: 2.2469 - val_accuracy: 0.1112 - val_loss: 2.5614\n",
      "Epoch 3/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 329ms/step - accuracy: 0.1477 - loss: 2.2900 - val_accuracy: 0.2045 - val_loss: 1.9675\n",
      "Epoch 4/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.2188 - loss: 1.7064 - val_accuracy: 0.2116 - val_loss: 1.9653\n",
      "Epoch 5/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 358ms/step - accuracy: 0.1369 - loss: 2.0617 - val_accuracy: 0.0800 - val_loss: 1.9648\n",
      "Epoch 6/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.1250 - loss: 1.6461 - val_accuracy: 0.0827 - val_loss: 1.9643\n",
      "Epoch 7/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 362ms/step - accuracy: 0.1525 - loss: 1.9563 - val_accuracy: 0.1861 - val_loss: 1.9231\n",
      "Epoch 8/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0938 - loss: 2.2678 - val_accuracy: 0.1820 - val_loss: 1.9233\n",
      "Epoch 9/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 332ms/step - accuracy: 0.1645 - loss: 1.9637 - val_accuracy: 0.1979 - val_loss: 1.8998\n",
      "Epoch 10/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.3750 - loss: 2.2418 - val_accuracy: 0.1972 - val_loss: 1.9006\n",
      "Epoch 11/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 383ms/step - accuracy: 0.1717 - loss: 1.9425 - val_accuracy: 0.1636 - val_loss: 1.9398\n",
      "Epoch 12/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.1875 - loss: 1.6910 - val_accuracy: 0.1644 - val_loss: 1.9397\n",
      "Epoch 13/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 377ms/step - accuracy: 0.1721 - loss: 1.9570 - val_accuracy: 0.1807 - val_loss: 1.9310\n",
      "Epoch 14/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 1.7069 - val_accuracy: 0.1795 - val_loss: 1.9324\n",
      "Epoch 15/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 367ms/step - accuracy: 0.1856 - loss: 1.9210 - val_accuracy: 0.1714 - val_loss: 2.0232\n",
      "Epoch 16/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.2188 - loss: 2.8589 - val_accuracy: 0.1714 - val_loss: 2.0198\n",
      "Epoch 17/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 372ms/step - accuracy: 0.1614 - loss: 1.9552 - val_accuracy: 0.2099 - val_loss: 1.9070\n",
      "Epoch 18/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.2812 - loss: 2.1506 - val_accuracy: 0.2097 - val_loss: 1.9063\n",
      "Epoch 19/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 381ms/step - accuracy: 0.1883 - loss: 1.9315 - val_accuracy: 0.1802 - val_loss: 1.9441\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), padding='same', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(emotions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(X_train) // 32,\n",
    "          epochs=100,\n",
    "          class_weight=class_weight_dict,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "model.save('primer_modelo.keras') #Para guardar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = './data/test_set.csv'  # Asegúrate de tener un CSV similar para el test set\n",
    "test_base_path = './data/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_images_from_csv(csv_path, base_path):\n",
    "    ids = read_csv(csv_path)\n",
    "    images = []\n",
    "    identificacion=[]\n",
    "\n",
    "    for _, row in ids.iterrows():\n",
    "        img_path = base_path+'/' + str(row[0])+'.jpg'\n",
    "        image_id = row[0]  \n",
    "        \n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('L')\n",
    "            images.append(np.array(img))\n",
    "            identificacion.append(image_id)\n",
    "    \n",
    "    return images, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_ids = load_test_images_from_csv(test_csv_path, test_base_path)\n",
    "test_images = normalize_images(test_images)\n",
    "test_images = np.expand_dims(test_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'id_img': test_ids['id_img'], 'label': predicted_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img     label\n",
       "0      10052       sad\n",
       "1      10065       sad\n",
       "2      10079  surprise\n",
       "3      10095       sad\n",
       "4      10121       sad\n",
       "...      ...       ...\n",
       "7061    9806     angry\n",
       "7062    9830       sad\n",
       "7063    9853       sad\n",
       "7064    9878   neutral\n",
       "7065     993   neutral\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('submision1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado:  0.18966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo Intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/train_set.csv'\n",
    "base_path = './data/images/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_images_from_csv(csv_path, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \n",
       "happy       5731\n",
       "neutral     3986\n",
       "sad         3950\n",
       "fear        3282\n",
       "angry       3194\n",
       "surprise    2564\n",
       "disgust      349\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'imagen':X_train,'id': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_happy=df[df['id']=='happy'].sample(n=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_neutral=df[df['id']=='neutral'].sample(n=3986)\n",
    "for i in range(4000-3986):\n",
    "    nuevo=df[df['id']=='neutral'].sample(n=1)\n",
    "    imagenes_neutral=pd.concat([imagenes_neutral,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_sad=df[df['id']=='sad'].sample(n=3950)\n",
    "for i in range(4000-3950):\n",
    "    nuevo=df[df['id']=='sad'].sample(n=1)\n",
    "    imagenes_sad=pd.concat([imagenes_sad,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_fear=df[df['id']=='fear'].sample(n=3282)\n",
    "for i in range(4000-3282):\n",
    "    nuevo=df[df['id']=='fear'].sample(n=1)\n",
    "    imagenes_fear=pd.concat([imagenes_fear,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_angry=df[df['id']=='angry'].sample(n=3194)\n",
    "for i in range(4000-3194):\n",
    "    nuevo=df[df['id']=='angry'].sample(n=1)\n",
    "    imagenes_angry=pd.concat([imagenes_angry,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_surprise=df[df['id']=='surprise'].sample(n=2564)\n",
    "for i in range(4000-2564):\n",
    "    nuevo=df[df['id']=='surprise'].sample(n=1)\n",
    "    imagenes_surprise=pd.concat([imagenes_surprise,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_disgust=df[df['id']=='disgust'].sample(n=349)\n",
    "for i in range(4000-349):\n",
    "    nuevo=df[df['id']=='disgust'].sample(n=1)\n",
    "    imagenes_disgust=pd.concat([imagenes_disgust,nuevo],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([imagenes_angry,imagenes_sad,imagenes_happy,imagenes_neutral,imagenes_fear,imagenes_disgust,imagenes_surprise],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['imagen']=df_train['imagen']/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imagen', 'id_angry', 'id_disgust', 'id_fear', 'id_happy', 'id_neutral',\n",
       "       'id_sad', 'id_surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_train, columns=['id']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.stack(df_train['imagen'])\n",
    "y_train=pd.get_dummies(df_train, columns=['id'])[['id_angry', 'id_disgust', 'id_fear', 'id_happy', 'id_neutral','id_sad', 'id_surprise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=np.array(X_val)/255\n",
    "y_val=pd.get_dummies(y_val, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 48, 48) (5765, 48, 48) (28000, 7) (5765, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_val.shape,y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 78ms/step - accuracy: 0.2749 - loss: 1.8437 - val_accuracy: 0.4184 - val_loss: 1.4771\n",
      "Epoch 2/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 79ms/step - accuracy: 0.5259 - loss: 1.2208 - val_accuracy: 0.4850 - val_loss: 1.3562\n",
      "Epoch 3/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 80ms/step - accuracy: 0.5931 - loss: 1.0523 - val_accuracy: 0.4925 - val_loss: 1.3328\n",
      "Epoch 4/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 80ms/step - accuracy: 0.6436 - loss: 0.9259 - val_accuracy: 0.5138 - val_loss: 1.3657\n",
      "Epoch 5/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 82ms/step - accuracy: 0.6950 - loss: 0.8103 - val_accuracy: 0.5006 - val_loss: 1.4419\n",
      "Epoch 6/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 80ms/step - accuracy: 0.7344 - loss: 0.7108 - val_accuracy: 0.5261 - val_loss: 1.4237\n",
      "Epoch 7/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 80ms/step - accuracy: 0.7692 - loss: 0.6207 - val_accuracy: 0.5204 - val_loss: 1.5295\n",
      "Epoch 8/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8034 - loss: 0.5383 - val_accuracy: 0.5379 - val_loss: 1.5465\n",
      "Epoch 9/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8327 - loss: 0.4617 - val_accuracy: 0.5289 - val_loss: 1.8401\n",
      "Epoch 10/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8535 - loss: 0.4139 - val_accuracy: 0.5382 - val_loss: 1.6747\n",
      "Epoch 11/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8762 - loss: 0.3628 - val_accuracy: 0.5292 - val_loss: 1.8916\n",
      "Epoch 12/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8862 - loss: 0.3206 - val_accuracy: 0.5464 - val_loss: 1.9435\n",
      "Epoch 13/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 81ms/step - accuracy: 0.8943 - loss: 0.2947 - val_accuracy: 0.5459 - val_loss: 1.8924\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', input_shape=(48, 48, 1), padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='sigmoid', kernel_initializer='he_uniform'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('segundo_modelo_check.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = load_model('segundo_modelo_check.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = './data/test_set.csv'  \n",
    "test_base_path = './data/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img     label\n",
       "0      10052       sad\n",
       "1      10065       sad\n",
       "2      10079      fear\n",
       "3      10095     angry\n",
       "4      10121     angry\n",
       "...      ...       ...\n",
       "7061    9806  surprise\n",
       "7062    9830       sad\n",
       "7063    9853  surprise\n",
       "7064    9878   neutral\n",
       "7065     993  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_test_images_from_csv(csv_path, base_path):\n",
    "    ids = read_csv(csv_path)\n",
    "    images = []\n",
    "    identificacion=[]\n",
    "\n",
    "    for _, row in ids.iterrows():\n",
    "        img_path = base_path+'/' + str(row[0])+'.jpg'\n",
    "        image_id = row[0]  \n",
    "        \n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('L')\n",
    "            images.append(np.array(img))\n",
    "            identificacion.append(image_id)\n",
    "    \n",
    "    return images, ids\n",
    "\n",
    "test_images, test_ids = load_test_images_from_csv(test_csv_path, test_base_path)\n",
    "test_images = normalize_images(test_images)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "output_df = pd.DataFrame({'id_img': test_ids['id_img'], 'label': predicted_labels})\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('submision2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado: 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 67ms/step - accuracy: 0.2915 - loss: 1.7989 - val_accuracy: 0.4002 - val_loss: 1.6985\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.5317 - loss: 1.2124 - val_accuracy: 0.4593 - val_loss: 1.4425\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.6024 - loss: 1.0378 - val_accuracy: 0.4774 - val_loss: 1.3985\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 70ms/step - accuracy: 0.6499 - loss: 0.9167 - val_accuracy: 0.5124 - val_loss: 1.3153\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.6875 - loss: 0.8163 - val_accuracy: 0.5154 - val_loss: 1.4343\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.7272 - loss: 0.7250 - val_accuracy: 0.5105 - val_loss: 1.4606\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.7604 - loss: 0.6394 - val_accuracy: 0.5480 - val_loss: 1.4706\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.7902 - loss: 0.5648 - val_accuracy: 0.5239 - val_loss: 1.6489\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8186 - loss: 0.4944 - val_accuracy: 0.5410 - val_loss: 1.6407\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8471 - loss: 0.4297 - val_accuracy: 0.5353 - val_loss: 1.7394\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8651 - loss: 0.3882 - val_accuracy: 0.5483 - val_loss: 1.7227\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.8783 - loss: 0.3427 - val_accuracy: 0.5192 - val_loss: 2.1959\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8914 - loss: 0.3074 - val_accuracy: 0.5313 - val_loss: 1.8536\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.8994 - loss: 0.2850 - val_accuracy: 0.5320 - val_loss: 1.9333\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9090 - loss: 0.2618 - val_accuracy: 0.5173 - val_loss: 2.0129\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9155 - loss: 0.2458 - val_accuracy: 0.5358 - val_loss: 2.2407\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9196 - loss: 0.2322 - val_accuracy: 0.5461 - val_loss: 1.9757\n",
      "Epoch 18/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9216 - loss: 0.2245 - val_accuracy: 0.5384 - val_loss: 2.2076\n",
      "Epoch 19/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - accuracy: 0.9287 - loss: 0.2082 - val_accuracy: 0.5384 - val_loss: 2.5719\n",
      "Epoch 20/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9339 - loss: 0.1939 - val_accuracy: 0.5329 - val_loss: 2.3772\n",
      "Epoch 21/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9353 - loss: 0.1889 - val_accuracy: 0.5313 - val_loss: 2.1909\n",
      "Epoch 22/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9361 - loss: 0.1848 - val_accuracy: 0.5393 - val_loss: 2.2834\n",
      "Epoch 23/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9425 - loss: 0.1746 - val_accuracy: 0.5448 - val_loss: 2.2717\n",
      "Epoch 24/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9421 - loss: 0.1656 - val_accuracy: 0.5533 - val_loss: 2.2129\n",
      "Epoch 25/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9453 - loss: 0.1611 - val_accuracy: 0.5292 - val_loss: 2.6395\n",
      "Epoch 26/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9464 - loss: 0.1567 - val_accuracy: 0.5329 - val_loss: 2.3258\n",
      "Epoch 27/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9506 - loss: 0.1440 - val_accuracy: 0.5344 - val_loss: 2.6223\n",
      "Epoch 28/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9518 - loss: 0.1371 - val_accuracy: 0.5216 - val_loss: 2.6717\n",
      "Epoch 29/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 96ms/step - accuracy: 0.9501 - loss: 0.1481 - val_accuracy: 0.5422 - val_loss: 2.6999\n",
      "Epoch 30/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9584 - loss: 0.1305 - val_accuracy: 0.5452 - val_loss: 2.5968\n",
      "Epoch 31/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9553 - loss: 0.1307 - val_accuracy: 0.5533 - val_loss: 2.5161\n",
      "Epoch 32/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9538 - loss: 0.1374 - val_accuracy: 0.5251 - val_loss: 2.5696\n",
      "Epoch 33/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9559 - loss: 0.1309 - val_accuracy: 0.5381 - val_loss: 2.4753\n",
      "Epoch 34/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9610 - loss: 0.1192 - val_accuracy: 0.5422 - val_loss: 2.6248\n",
      "Epoch 35/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9581 - loss: 0.1223 - val_accuracy: 0.5362 - val_loss: 2.8102\n",
      "Epoch 36/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9568 - loss: 0.1255 - val_accuracy: 0.5502 - val_loss: 2.6248\n",
      "Epoch 37/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9604 - loss: 0.1184 - val_accuracy: 0.5448 - val_loss: 2.5402\n",
      "Epoch 38/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9615 - loss: 0.1146 - val_accuracy: 0.5424 - val_loss: 2.6474\n",
      "Epoch 39/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9621 - loss: 0.1123 - val_accuracy: 0.5611 - val_loss: 2.4125\n",
      "Epoch 40/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9625 - loss: 0.1115 - val_accuracy: 0.5507 - val_loss: 2.8123\n",
      "Epoch 41/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9651 - loss: 0.1099 - val_accuracy: 0.5584 - val_loss: 2.6371\n",
      "Epoch 42/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9641 - loss: 0.1063 - val_accuracy: 0.5471 - val_loss: 2.8279\n",
      "Epoch 43/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9658 - loss: 0.1047 - val_accuracy: 0.5363 - val_loss: 2.7040\n",
      "Epoch 44/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9645 - loss: 0.1041 - val_accuracy: 0.5332 - val_loss: 2.7443\n",
      "Epoch 45/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9647 - loss: 0.1016 - val_accuracy: 0.5481 - val_loss: 2.8471\n",
      "Epoch 46/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9669 - loss: 0.1008 - val_accuracy: 0.5483 - val_loss: 2.8508\n",
      "Epoch 47/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9662 - loss: 0.1015 - val_accuracy: 0.5568 - val_loss: 2.7851\n",
      "Epoch 48/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9681 - loss: 0.0968 - val_accuracy: 0.5488 - val_loss: 2.6736\n",
      "Epoch 49/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9711 - loss: 0.0932 - val_accuracy: 0.5485 - val_loss: 2.7505\n",
      "Epoch 50/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9679 - loss: 0.0950 - val_accuracy: 0.5377 - val_loss: 2.8721\n",
      "Epoch 51/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9703 - loss: 0.0881 - val_accuracy: 0.5499 - val_loss: 2.8670\n",
      "Epoch 52/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9732 - loss: 0.0854 - val_accuracy: 0.5504 - val_loss: 2.8251\n",
      "Epoch 53/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9672 - loss: 0.0969 - val_accuracy: 0.5523 - val_loss: 2.7102\n",
      "Epoch 54/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9705 - loss: 0.0882 - val_accuracy: 0.5247 - val_loss: 2.9591\n",
      "Epoch 55/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9717 - loss: 0.0841 - val_accuracy: 0.5490 - val_loss: 2.8468\n",
      "Epoch 56/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9736 - loss: 0.0816 - val_accuracy: 0.5337 - val_loss: 2.8892\n",
      "Epoch 57/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9719 - loss: 0.0816 - val_accuracy: 0.5391 - val_loss: 3.0582\n",
      "Epoch 58/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9727 - loss: 0.0860 - val_accuracy: 0.5532 - val_loss: 2.9652\n",
      "Epoch 59/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 67ms/step - accuracy: 0.9732 - loss: 0.0836 - val_accuracy: 0.5346 - val_loss: 2.9606\n",
      "Epoch 60/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 67ms/step - accuracy: 0.9742 - loss: 0.0812 - val_accuracy: 0.5422 - val_loss: 2.9516\n",
      "Epoch 61/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9773 - loss: 0.0701 - val_accuracy: 0.5552 - val_loss: 3.0745\n",
      "Epoch 62/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9742 - loss: 0.0784 - val_accuracy: 0.5438 - val_loss: 2.9132\n",
      "Epoch 63/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.9751 - loss: 0.0766 - val_accuracy: 0.5516 - val_loss: 3.0308\n",
      "Epoch 64/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9763 - loss: 0.0716 - val_accuracy: 0.5467 - val_loss: 3.1284\n",
      "Epoch 65/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - accuracy: 0.9737 - loss: 0.0778 - val_accuracy: 0.5500 - val_loss: 3.1576\n",
      "Epoch 66/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.9777 - loss: 0.0681 - val_accuracy: 0.5408 - val_loss: 3.0647\n",
      "Epoch 67/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9783 - loss: 0.0665 - val_accuracy: 0.5412 - val_loss: 2.9174\n",
      "Epoch 68/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9763 - loss: 0.0709 - val_accuracy: 0.5539 - val_loss: 3.0354\n",
      "Epoch 69/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9757 - loss: 0.0744 - val_accuracy: 0.5530 - val_loss: 3.1357\n",
      "Epoch 70/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9785 - loss: 0.0685 - val_accuracy: 0.5544 - val_loss: 3.1022\n",
      "Epoch 71/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 77ms/step - accuracy: 0.9778 - loss: 0.0654 - val_accuracy: 0.5539 - val_loss: 2.9465\n",
      "Epoch 72/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9781 - loss: 0.0645 - val_accuracy: 0.5499 - val_loss: 3.1486\n",
      "Epoch 73/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9791 - loss: 0.0664 - val_accuracy: 0.5492 - val_loss: 3.0943\n",
      "Epoch 74/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9809 - loss: 0.0590 - val_accuracy: 0.5443 - val_loss: 3.0927\n",
      "Epoch 75/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - accuracy: 0.9784 - loss: 0.0660 - val_accuracy: 0.5481 - val_loss: 3.3448\n",
      "Epoch 76/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 81ms/step - accuracy: 0.9786 - loss: 0.0637 - val_accuracy: 0.5525 - val_loss: 3.1357\n",
      "Epoch 77/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9799 - loss: 0.0628 - val_accuracy: 0.5343 - val_loss: 3.3668\n",
      "Epoch 78/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9810 - loss: 0.0594 - val_accuracy: 0.5408 - val_loss: 3.1017\n",
      "Epoch 79/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9786 - loss: 0.0671 - val_accuracy: 0.5577 - val_loss: 3.2104\n",
      "Epoch 80/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9797 - loss: 0.0660 - val_accuracy: 0.5464 - val_loss: 3.2668\n",
      "Epoch 81/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.9805 - loss: 0.0581 - val_accuracy: 0.5379 - val_loss: 3.1605\n",
      "Epoch 82/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - accuracy: 0.9822 - loss: 0.0554 - val_accuracy: 0.5497 - val_loss: 3.4154\n",
      "Epoch 83/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 78ms/step - accuracy: 0.9809 - loss: 0.0605 - val_accuracy: 0.5506 - val_loss: 3.2402\n",
      "Epoch 84/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9798 - loss: 0.0653 - val_accuracy: 0.5467 - val_loss: 3.3895\n",
      "Epoch 85/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9813 - loss: 0.0617 - val_accuracy: 0.5533 - val_loss: 3.2347\n",
      "Epoch 86/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9811 - loss: 0.0563 - val_accuracy: 0.5504 - val_loss: 3.2175\n",
      "Epoch 87/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9820 - loss: 0.0571 - val_accuracy: 0.5565 - val_loss: 3.0883\n",
      "Epoch 88/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 78ms/step - accuracy: 0.9832 - loss: 0.0547 - val_accuracy: 0.5606 - val_loss: 3.1051\n",
      "Epoch 89/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9834 - loss: 0.0502 - val_accuracy: 0.5513 - val_loss: 3.3011\n",
      "Epoch 90/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9848 - loss: 0.0476 - val_accuracy: 0.5520 - val_loss: 3.3199\n",
      "Epoch 91/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9816 - loss: 0.0547 - val_accuracy: 0.5511 - val_loss: 3.3983\n",
      "Epoch 92/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9831 - loss: 0.0529 - val_accuracy: 0.5544 - val_loss: 3.4071\n",
      "Epoch 93/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9812 - loss: 0.0594 - val_accuracy: 0.5481 - val_loss: 3.4427\n",
      "Epoch 94/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9800 - loss: 0.0578 - val_accuracy: 0.5587 - val_loss: 3.3390\n",
      "Epoch 95/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9828 - loss: 0.0520 - val_accuracy: 0.5431 - val_loss: 3.2828\n",
      "Epoch 96/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 79ms/step - accuracy: 0.9843 - loss: 0.0475 - val_accuracy: 0.5533 - val_loss: 3.2989\n",
      "Epoch 97/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - accuracy: 0.9820 - loss: 0.0563 - val_accuracy: 0.5464 - val_loss: 3.3886\n",
      "Epoch 98/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - accuracy: 0.9848 - loss: 0.0488 - val_accuracy: 0.5558 - val_loss: 3.3323\n",
      "Epoch 99/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 80ms/step - accuracy: 0.9846 - loss: 0.0465 - val_accuracy: 0.5540 - val_loss: 3.3703\n",
      "Epoch 100/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - accuracy: 0.9859 - loss: 0.0433 - val_accuracy: 0.5644 - val_loss: 3.3938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27daeb7c250>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', input_shape=(48, 48, 1), padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='sigmoid', kernel_initializer='he_uniform'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('tercer_modelo.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    batch_size=32,\n",
    "                    steps_per_epoch=1000,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img     label\n",
       "0      10052   neutral\n",
       "1      10065       sad\n",
       "2      10079     angry\n",
       "3      10095     angry\n",
       "4      10121     angry\n",
       "...      ...       ...\n",
       "7061    9806  surprise\n",
       "7062    9830     happy\n",
       "7063    9853  surprise\n",
       "7064    9878  surprise\n",
       "7065     993  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = load_model('tercer_modelo.keras')\n",
    "\n",
    "test_csv_path = './data/test_set.csv'  \n",
    "test_base_path = './data/images/test'\n",
    "\n",
    "def load_test_images_from_csv(csv_path, base_path):\n",
    "    ids = read_csv(csv_path)\n",
    "    images = []\n",
    "    identificacion=[]\n",
    "\n",
    "    for _, row in ids.iterrows():\n",
    "        img_path = base_path+'/' + str(row[0])+'.jpg'\n",
    "        image_id = row[0]  \n",
    "        \n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('L')\n",
    "            images.append(np.array(img))\n",
    "            identificacion.append(image_id)\n",
    "    \n",
    "    return images, ids\n",
    "\n",
    "test_images, test_ids = load_test_images_from_csv(test_csv_path, test_base_path)\n",
    "test_images = normalize_images(test_images)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "output_df = pd.DataFrame({'id_img': test_ids['id_img'], 'label': predicted_labels})\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('submision3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado: 0.52052"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuarta Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/train_set.csv'\n",
    "base_path = './data/images/train'\n",
    "train_images, train_labels = load_images_from_csv(csv_path, base_path)\n",
    "train_images, train_labels = preprocess_data(train_images, train_labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
    "# Calcular los pesos de clase\n",
    "numeric_labels = encode_labels([label_encoder.inverse_transform([np.argmax(label)])[0] for label in train_labels])\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(numeric_labels), y=numeric_labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(emotions))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.031125898894494,\n",
       " 1: 9.443315858453474,\n",
       " 2: 1.0034817729187702,\n",
       " 3: 0.5747188322565207,\n",
       " 4: 0.8264322991340254,\n",
       " 5: 0.8337962159347335,\n",
       " 6: 1.2846445286382884}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23056, 48, 48)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 60ms/step - accuracy: 0.2368 - loss: 1.9726 - val_accuracy: 0.2486 - val_loss: 1.8865\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.3857 - loss: 1.5805 - val_accuracy: 0.3984 - val_loss: 1.6135\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.4552 - loss: 1.4056 - val_accuracy: 0.4234 - val_loss: 1.4275\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 75ms/step - accuracy: 0.4961 - loss: 1.2817 - val_accuracy: 0.4656 - val_loss: 1.3900\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 66ms/step - accuracy: 0.5220 - loss: 1.1979 - val_accuracy: 0.4982 - val_loss: 1.3664\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 68ms/step - accuracy: 0.5499 - loss: 1.1197 - val_accuracy: 0.5084 - val_loss: 1.3216\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.5802 - loss: 1.0346 - val_accuracy: 0.5256 - val_loss: 1.2803\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 72ms/step - accuracy: 0.6005 - loss: 0.9566 - val_accuracy: 0.5273 - val_loss: 1.3244\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.6265 - loss: 0.9110 - val_accuracy: 0.5200 - val_loss: 1.3062\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.6479 - loss: 0.8453 - val_accuracy: 0.5294 - val_loss: 1.3069\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 73ms/step - accuracy: 0.6663 - loss: 0.8039 - val_accuracy: 0.4999 - val_loss: 1.4695\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 63ms/step - accuracy: 0.6921 - loss: 0.7470 - val_accuracy: 0.5334 - val_loss: 1.3917\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.7182 - loss: 0.6703 - val_accuracy: 0.5393 - val_loss: 1.4612\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.7437 - loss: 0.6165 - val_accuracy: 0.5317 - val_loss: 1.4900\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.7671 - loss: 0.5648 - val_accuracy: 0.5407 - val_loss: 1.5997\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.7825 - loss: 0.5291 - val_accuracy: 0.5219 - val_loss: 1.7285\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8033 - loss: 0.4900 - val_accuracy: 0.5289 - val_loss: 1.6370\n",
      "Epoch 18/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8171 - loss: 0.4457 - val_accuracy: 0.5296 - val_loss: 1.7505\n",
      "Epoch 19/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8366 - loss: 0.4077 - val_accuracy: 0.5192 - val_loss: 1.8942\n",
      "Epoch 20/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 62ms/step - accuracy: 0.8468 - loss: 0.3805 - val_accuracy: 0.5344 - val_loss: 1.9092\n",
      "Epoch 21/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.8587 - loss: 0.3593 - val_accuracy: 0.5266 - val_loss: 1.8794\n",
      "Epoch 22/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8646 - loss: 0.3345 - val_accuracy: 0.4820 - val_loss: 2.0732\n",
      "Epoch 23/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8708 - loss: 0.3205 - val_accuracy: 0.5296 - val_loss: 1.9690\n",
      "Epoch 24/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8800 - loss: 0.3083 - val_accuracy: 0.5256 - val_loss: 2.1011\n",
      "Epoch 25/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8860 - loss: 0.2868 - val_accuracy: 0.5358 - val_loss: 2.2777\n",
      "Epoch 26/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8915 - loss: 0.2770 - val_accuracy: 0.5183 - val_loss: 2.2109\n",
      "Epoch 27/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.8998 - loss: 0.2498 - val_accuracy: 0.5136 - val_loss: 2.1358\n",
      "Epoch 28/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 58ms/step - accuracy: 0.9013 - loss: 0.2503 - val_accuracy: 0.5212 - val_loss: 2.0703\n",
      "Epoch 29/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9074 - loss: 0.2341 - val_accuracy: 0.5376 - val_loss: 2.1575\n",
      "Epoch 30/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9082 - loss: 0.2252 - val_accuracy: 0.5143 - val_loss: 2.4090\n",
      "Epoch 31/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9134 - loss: 0.2301 - val_accuracy: 0.5421 - val_loss: 2.3012\n",
      "Epoch 32/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 71ms/step - accuracy: 0.9190 - loss: 0.2126 - val_accuracy: 0.5412 - val_loss: 2.2638\n",
      "Epoch 33/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9194 - loss: 0.2092 - val_accuracy: 0.5459 - val_loss: 2.4537\n",
      "Epoch 34/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9231 - loss: 0.2112 - val_accuracy: 0.5239 - val_loss: 2.4087\n",
      "Epoch 35/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9249 - loss: 0.1940 - val_accuracy: 0.5343 - val_loss: 2.5347\n",
      "Epoch 36/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9255 - loss: 0.1966 - val_accuracy: 0.5301 - val_loss: 2.3921\n",
      "Epoch 37/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58ms/step - accuracy: 0.9276 - loss: 0.2118 - val_accuracy: 0.5310 - val_loss: 2.3995\n",
      "Epoch 38/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 58ms/step - accuracy: 0.9273 - loss: 0.1882 - val_accuracy: 0.5436 - val_loss: 2.4037\n",
      "Epoch 39/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9295 - loss: 0.1833 - val_accuracy: 0.5400 - val_loss: 2.3764\n",
      "Epoch 40/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9355 - loss: 0.1750 - val_accuracy: 0.5376 - val_loss: 2.6405\n",
      "Epoch 41/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9357 - loss: 0.1673 - val_accuracy: 0.5422 - val_loss: 2.6458\n",
      "Epoch 42/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9320 - loss: 0.1839 - val_accuracy: 0.5552 - val_loss: 2.5305\n",
      "Epoch 43/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9388 - loss: 0.1665 - val_accuracy: 0.5353 - val_loss: 2.3972\n",
      "Epoch 44/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9393 - loss: 0.1621 - val_accuracy: 0.5516 - val_loss: 2.7674\n",
      "Epoch 45/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9386 - loss: 0.1662 - val_accuracy: 0.5256 - val_loss: 2.7094\n",
      "Epoch 46/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9371 - loss: 0.1688 - val_accuracy: 0.5428 - val_loss: 2.6600\n",
      "Epoch 47/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9406 - loss: 0.1654 - val_accuracy: 0.5464 - val_loss: 2.4966\n",
      "Epoch 48/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9440 - loss: 0.1535 - val_accuracy: 0.5526 - val_loss: 2.5731\n",
      "Epoch 49/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9422 - loss: 0.1597 - val_accuracy: 0.5568 - val_loss: 2.4777\n",
      "Epoch 50/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9447 - loss: 0.1442 - val_accuracy: 0.5382 - val_loss: 2.4111\n",
      "Epoch 51/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9476 - loss: 0.1489 - val_accuracy: 0.5511 - val_loss: 2.7369\n",
      "Epoch 52/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9449 - loss: 0.1467 - val_accuracy: 0.5502 - val_loss: 2.5234\n",
      "Epoch 53/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9447 - loss: 0.1538 - val_accuracy: 0.5540 - val_loss: 2.7537\n",
      "Epoch 54/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9480 - loss: 0.1420 - val_accuracy: 0.5369 - val_loss: 2.6640\n",
      "Epoch 55/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 60ms/step - accuracy: 0.9492 - loss: 0.1339 - val_accuracy: 0.5474 - val_loss: 2.7322\n",
      "Epoch 56/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9487 - loss: 0.1487 - val_accuracy: 0.5407 - val_loss: 2.4759\n",
      "Epoch 57/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59ms/step - accuracy: 0.9475 - loss: 0.1429 - val_accuracy: 0.5544 - val_loss: 2.6267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c6ee2cd60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', input_shape=(48, 48, 1), padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_uniform'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='sigmoid', kernel_initializer='he_uniform'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('cuarto_modelo.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    class_weight=class_weight_dict,\n",
    "                    batch_size=32,\n",
    "                    steps_per_epoch=1000,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10052</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10079</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10095</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10121</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>9806</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>9830</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>9853</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>9878</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>993</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img     label\n",
       "0      10052   neutral\n",
       "1      10065       sad\n",
       "2      10079     angry\n",
       "3      10095     angry\n",
       "4      10121   disgust\n",
       "...      ...       ...\n",
       "7061    9806  surprise\n",
       "7062    9830  surprise\n",
       "7063    9853  surprise\n",
       "7064    9878     happy\n",
       "7065     993  surprise\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "model = load_model('tercer_modelo.keras')\n",
    "\n",
    "test_csv_path = './data/test_set.csv'  \n",
    "test_base_path = './data/images/test'\n",
    "\n",
    "def load_test_images_from_csv(csv_path, base_path):\n",
    "    ids = read_csv(csv_path)\n",
    "    images = []\n",
    "    identificacion=[]\n",
    "\n",
    "    for _, row in ids.iterrows():\n",
    "        img_path = base_path+'/' + str(row[0])+'.jpg'\n",
    "        image_id = row[0]  \n",
    "        \n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert('L')\n",
    "            images.append(np.array(img))\n",
    "            identificacion.append(image_id)\n",
    "    \n",
    "    return images, ids\n",
    "\n",
    "test_images, test_ids = load_test_images_from_csv(test_csv_path, test_base_path)\n",
    "test_images = normalize_images(test_images)\n",
    "test_images = np.expand_dims(test_images, -1)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "output_df = pd.DataFrame({'id_img': test_ids['id_img'], 'label': predicted_labels})\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('submision4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
